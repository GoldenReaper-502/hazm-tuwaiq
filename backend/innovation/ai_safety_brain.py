"""
AI Safety Brain - Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ Ù„Ù„Ø³Ù„Ø§Ù…Ø©
Ù†Ø¸Ø§Ù… Ø°ÙƒØ§Ø¡ Ù…Ø±ÙƒØ²ÙŠ ÙŠØªØ¹Ù„Ù… Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« ÙˆÙŠØ¨Ù†ÙŠ Ø°Ø§ÙƒØ±Ø© Ù…Ø¤Ø³Ø³ÙŠØ©
"""
import json
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from collections import defaultdict
import numpy as np


@dataclass
class IncidentMemory:
    """Ø°Ø§ÙƒØ±Ø© Ø­Ø§Ø¯Ø«"""
    id: str
    timestamp: datetime
    incident_type: str
    location: str
    severity: float
    root_causes: List[str]
    consequences: List[str]
    lessons_learned: List[str]
    prevention_measures: List[str]


@dataclass
class NearMiss:
    """Ø­Ø§Ø¯Ø« ÙƒØ§Ø¯ Ø£Ù† ÙŠÙ‚Ø¹"""
    id: str
    timestamp: datetime
    description: str
    potential_severity: float
    prevented_by: List[str]
    insights: List[str]


@dataclass
class BehaviorPattern:
    """Ù†Ù…Ø· Ø³Ù„ÙˆÙƒÙŠ"""
    pattern_id: str
    description: str
    risk_level: float
    frequency: int
    contexts: List[str]
    recommendations: List[str]


class AISafetyBrain:
    """Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ Ù„Ù„Ø³Ù„Ø§Ù…Ø©"""
    
    def __init__(self):
        self.incident_memory: List[IncidentMemory] = []
        self.near_misses: List[NearMiss] = []
        self.behavior_patterns: Dict[str, BehaviorPattern] = {}
        self.organizational_memory = {
            "total_incidents": 0,
            "total_near_misses": 0,
            "patterns_identified": 0,
            "lives_saved": 0,
            "cost_prevented": 0
        }
        self.learning_insights = []
        self.project_knowledge = defaultdict(dict)
        
    def learn_from_incident(self, incident_data: Dict[str, Any]) -> Dict:
        """Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø­Ø§Ø¯Ø«"""
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø­Ø§Ø¯Ø«
        incident = IncidentMemory(
            id=incident_data.get('id', f"inc_{datetime.now().timestamp()}"),
            timestamp=datetime.fromisoformat(incident_data.get('timestamp', datetime.now().isoformat())),
            incident_type=incident_data.get('type'),
            location=incident_data.get('location'),
            severity=incident_data.get('severity', 5.0),
            root_causes=incident_data.get('root_causes', []),
            consequences=incident_data.get('consequences', []),
            lessons_learned=[],
            prevention_measures=[]
        )
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø§Ø¯Ø« Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        analysis = self._analyze_incident(incident)
        
        # Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¯Ø±ÙˆØ³
        incident.lessons_learned = self._extract_lessons(incident, analysis)
        incident.prevention_measures = self._generate_preventions(incident, analysis)
        
        # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        self.incident_memory.append(incident)
        self.organizational_memory["total_incidents"] += 1
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ù…Ø´Ø§Ø¨Ù‡Ø©
        similar_incidents = self._find_similar_incidents(incident)
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠØ©
        self._update_organizational_knowledge(incident)
        
        return {
            "incident_id": incident.id,
            "lessons_learned": incident.lessons_learned,
            "prevention_measures": incident.prevention_measures,
            "similar_incidents_count": len(similar_incidents),
            "similar_incidents": similar_incidents[:5],  # Ø£ÙˆÙ„ 5
            "pattern_detected": len(similar_incidents) >= 3,
            "recommendations": self._generate_smart_recommendations(incident, similar_incidents),
            "organizational_impact": self._assess_organizational_impact(incident)
        }
    
    def learn_from_near_miss(self, near_miss_data: Dict[str, Any]) -> Dict:
        """Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø­Ø§Ø¯Ø« ÙƒØ§Ø¯ Ø£Ù† ÙŠÙ‚Ø¹"""
        
        near_miss = NearMiss(
            id=near_miss_data.get('id', f"nm_{datetime.now().timestamp()}"),
            timestamp=datetime.fromisoformat(near_miss_data.get('timestamp', datetime.now().isoformat())),
            description=near_miss_data.get('description'),
            potential_severity=near_miss_data.get('potential_severity', 7.0),
            prevented_by=near_miss_data.get('prevented_by', []),
            insights=[]
        )
        
        # ØªØ­Ù„ÙŠÙ„ Ù…Ø§ Ø§Ù„Ø°ÙŠ Ù…Ù†Ø¹ ÙˆÙ‚ÙˆØ¹ Ø§Ù„Ø­Ø§Ø¯Ø«
        prevention_analysis = self._analyze_prevention_success(near_miss)
        
        near_miss.insights = prevention_analysis['insights']
        
        self.near_misses.append(near_miss)
        self.organizational_memory["total_near_misses"] += 1
        self.organizational_memory["lives_saved"] += int(near_miss.potential_severity / 2)
        
        return {
            "near_miss_id": near_miss.id,
            "insights": near_miss.insights,
            "success_factors": prevention_analysis['success_factors'],
            "replication_guide": prevention_analysis['replication_guide'],
            "value": f"Ù…Ù†Ø¹ Ø­Ø§Ø¯Ø« Ù…Ø­ØªÙ…Ù„ Ø¨Ø´Ø¯Ø© {near_miss.potential_severity}/10"
        }
    
    def learn_from_behavior(self, behavior_data: Dict[str, Any]) -> Dict:
        """Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø³Ù„ÙˆÙƒ Ø§Ù„Ø¹Ù…Ø§Ù„"""
        
        behavior_type = behavior_data.get('behavior_type')
        risk_level = behavior_data.get('risk_level', 0)
        context = behavior_data.get('context', 'unknown')
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù…Ø· Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙŠØ¯
        pattern_key = f"{behavior_type}_{context}"
        
        if pattern_key in self.behavior_patterns:
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
            pattern = self.behavior_patterns[pattern_key]
            pattern.frequency += 1
            pattern.risk_level = (pattern.risk_level + risk_level) / 2  # Ù…ØªÙˆØ³Ø· Ù…ØªØ­Ø±Ùƒ
        else:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…Ø· Ø¬Ø¯ÙŠØ¯
            pattern = BehaviorPattern(
                pattern_id=pattern_key,
                description=behavior_data.get('description', ''),
                risk_level=risk_level,
                frequency=1,
                contexts=[context],
                recommendations=self._generate_behavior_recommendations(behavior_type, risk_level)
            )
            self.behavior_patterns[pattern_key] = pattern
            self.organizational_memory["patterns_identified"] += 1
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡
        trend = self._analyze_behavior_trend(pattern)
        
        return {
            "pattern_id": pattern.pattern_id,
            "frequency": pattern.frequency,
            "risk_level": round(pattern.risk_level, 2),
            "trend": trend,
            "is_concerning": pattern.risk_level > 60 and pattern.frequency > 10,
            "recommendations": pattern.recommendations,
            "intervention_needed": self._assess_intervention_need(pattern)
        }
    
    def build_organizational_memory(self) -> Dict:
        """Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠØ©"""
        
        if not self.incident_memory and not self.near_misses:
            return {
                "status": "insufficient_data",
                "message": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠØ©"
            }
        
        # ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„
        memory = {
            "total_learning_events": len(self.incident_memory) + len(self.near_misses),
            "incidents_analyzed": len(self.incident_memory),
            "near_misses_captured": len(self.near_misses),
            "patterns_identified": len(self.behavior_patterns),
            "lives_saved": self.organizational_memory["lives_saved"],
            
            # Ø£ÙƒØ«Ø± Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø´ÙŠÙˆØ¹Ø§Ù‹
            "most_common_incident_types": self._get_most_common_incidents(),
            
            # Ø£ÙƒØ«Ø± Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠØ©
            "top_root_causes": self._get_top_root_causes(),
            
            # Ø£ÙƒØ«Ø± Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ÙˆÙ‚Ø§Ø¦ÙŠØ© ÙØ¹Ø§Ù„ÙŠØ©
            "most_effective_preventions": self._get_effective_preventions(),
            
            # Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            "key_lessons": self._compile_key_lessons(),
            
            # ØªÙˆØµÙŠØ§Øª Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©
            "strategic_recommendations": self._generate_strategic_recommendations(),
            
            # Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡
            "performance_metrics": self._calculate_performance_metrics(),
            
            # Ø§Ù„ØªØ­Ø³Ù† Ù…Ø¹ Ø§Ù„ÙˆÙ‚Øª
            "improvement_over_time": self._track_improvement()
        }
        
        return memory
    
    def apply_learning_to_new_project(self, project_config: Dict) -> Dict:
        """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¹Ù„Ù… Ø¹Ù„Ù‰ Ù…Ø´Ø±ÙˆØ¹ Ø¬Ø¯ÙŠØ¯"""
        
        project_type = project_config.get('type')
        project_location = project_config.get('location')
        project_scale = project_config.get('scale')
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø´Ø§Ø±ÙŠØ¹ Ù…Ø´Ø§Ø¨Ù‡Ø©
        similar_projects = self._find_similar_projects(project_config)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ù…Ø·Ø¨Ù‚Ø©
        applicable_lessons = []
        for incident in self.incident_memory:
            if self._is_relevant_to_project(incident, project_config):
                applicable_lessons.extend(incident.lessons_learned)
        
        # Ø¨Ù†Ø§Ø¡ Ø®Ø·Ø© Ø³Ù„Ø§Ù…Ø© Ø°ÙƒÙŠØ©
        safety_plan = self._generate_smart_safety_plan(project_config, applicable_lessons)
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
        predicted_risks = self._predict_project_risks(project_config)
        
        # Ø­ÙØ¸ ÙÙŠ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
        project_id = project_config.get('id', f"proj_{datetime.now().timestamp()}")
        self.project_knowledge[project_id] = {
            "config": project_config,
            "safety_plan": safety_plan,
            "predicted_risks": predicted_risks,
            "start_date": datetime.now().isoformat()
        }
        
        return {
            "project_id": project_id,
            "similar_projects_analyzed": len(similar_projects),
            "lessons_applied": len(set(applicable_lessons)),
            "safety_plan": safety_plan,
            "predicted_risks": predicted_risks,
            "expected_safety_improvement": self._estimate_safety_improvement(
                project_config, applicable_lessons
            ),
            "message": "ÙƒÙ„ Ù…Ø´Ø±ÙˆØ¹ Ø¬Ø¯ÙŠØ¯ ÙŠØ¨Ø¯Ø£ Ø£ÙƒØ«Ø± Ø£Ù…Ø§Ù†Ù‹Ø§ Ù…Ù† Ø§Ù„Ø³Ø§Ø¨Ù‚ ğŸ¯"
        }
    
    def get_cross_project_insights(self) -> Dict:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø¤Ù‰ Ø¹Ø¨Ø± Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹"""
        
        if len(self.project_knowledge) < 2:
            return {
                "status": "insufficient_projects",
                "message": "ÙŠØ¬Ø¨ ÙˆØ¬ÙˆØ¯ Ù…Ø´Ø±ÙˆØ¹ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©"
            }
        
        insights = {
            "total_projects": len(self.project_knowledge),
            "common_success_factors": self._identify_success_factors(),
            "common_failure_points": self._identify_failure_points(),
            "best_practices": self._extract_best_practices(),
            "risk_patterns_across_projects": self._analyze_cross_project_risks(),
            "recommendations_for_future": self._generate_future_recommendations()
        }
        
        return insights
    
    # ===== ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© =====
    
    def _analyze_incident(self, incident: IncidentMemory) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø§Ø¯Ø«"""
        return {
            "severity_category": "critical" if incident.severity > 7 else "moderate" if incident.severity > 4 else "minor",
            "preventability": 0.8,  # ØªÙ‚Ø¯ÙŠØ±
            "similar_count": len(self._find_similar_incidents(incident))
        }
    
    def _extract_lessons(self, incident: IncidentMemory, analysis: Dict) -> List[str]:
        """Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¯Ø±ÙˆØ³"""
        lessons = []
        
        # Ø¯Ø±ÙˆØ³ Ù…Ù† Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠØ©
        for cause in incident.root_causes:
            if "ØªØ¯Ø±ÙŠØ¨" in cause or "training" in cause.lower():
                lessons.append("Ø£Ù‡Ù…ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³ØªÙ…Ø± ÙˆØ§Ù„Ø´Ø§Ù…Ù„")
            if "Ù…Ø¹Ø¯Ø§Øª" in cause or "equipment" in cause.lower():
                lessons.append("Ø¶Ø±ÙˆØ±Ø© Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„Ø¯ÙˆØ±ÙŠØ© Ù„Ù„Ù…Ø¹Ø¯Ø§Øª")
            if "Ø¥Ø¬Ø±Ø§Ø¡" in cause or "procedure" in cause.lower():
                lessons.append("Ø£Ù‡Ù…ÙŠØ© Ø§ØªØ¨Ø§Ø¹ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…ÙˆØ­Ø¯Ø©")
        
        # Ø¯Ø±ÙˆØ³ Ø¹Ø§Ù…Ø©
        if incident.severity > 7:
            lessons.append("Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ø®Ø·ÙŠØ±Ø© ÙŠÙ…ÙƒÙ† Ù…Ù†Ø¹Ù‡Ø§ Ø¨Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø§Ø³ØªØ¨Ø§Ù‚ÙŠØ©")
        
        return lessons if lessons else ["ØªØ­ØªØ§Ø¬ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¯Ø±ÙˆØ³"]
    
    def _generate_preventions(self, incident: IncidentMemory, analysis: Dict) -> List[str]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ÙˆÙ‚Ø§Ø¦ÙŠØ©"""
        preventions = []
        
        # Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø­Ø§Ø¯Ø«
        incident_type_lower = incident.incident_type.lower()
        
        if "Ø³Ù‚ÙˆØ·" in incident.incident_type or "fall" in incident_type_lower:
            preventions.extend([
                "ØªØ±ÙƒÙŠØ¨ Ø­ÙˆØ§Ø¬Ø² Ø³Ù„Ø§Ù…Ø©",
                "ÙØ­Øµ Ù…Ø¹Ø¯Ø§Øª Ø§Ù„Ø­Ù…Ø§ÙŠØ© ÙŠÙˆÙ…ÙŠØ§Ù‹",
                "ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø³Ù„Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø±ØªÙØ¹Ø§Øª"
            ])
        elif "Ø­Ø±ÙŠÙ‚" in incident.incident_type or "fire" in incident_type_lower:
            preventions.extend([
                "ÙØ­Øµ Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø¥Ù†Ø°Ø§Ø±",
                "ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¥Ø®Ù„Ø§Ø¡ Ø§Ù„Ø¯ÙˆØ±ÙŠ",
                "ØªØ­Ø¯ÙŠØ« Ø®Ø·Ø· Ø§Ù„Ø·ÙˆØ§Ø±Ø¦"
            ])
        else:
            preventions.extend([
                "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª",
                "ØªØ¹Ø²ÙŠØ² Ø§Ù„ØªØ¯Ø±ÙŠØ¨",
                "Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªÙØªÙŠØ´"
            ])
        
        return preventions
    
    def _find_similar_incidents(self, incident: IncidentMemory) -> List[Dict]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø­ÙˆØ§Ø¯Ø« Ù…Ø´Ø§Ø¨Ù‡Ø©"""
        similar = []
        
        for past_incident in self.incident_memory:
            if past_incident.id == incident.id:
                continue
            
            # Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†ÙˆØ¹ ÙˆØ§Ù„Ù…ÙˆÙ‚Ø¹
            similarity_score = 0
            if past_incident.incident_type == incident.incident_type:
                similarity_score += 50
            if past_incident.location == incident.location:
                similarity_score += 30
            if abs(past_incident.severity - incident.severity) < 2:
                similarity_score += 20
            
            if similarity_score >= 50:
                similar.append({
                    "id": past_incident.id,
                    "type": past_incident.incident_type,
                    "date": past_incident.timestamp.isoformat(),
                    "similarity": similarity_score
                })
        
        return sorted(similar, key=lambda x: x['similarity'], reverse=True)
    
    def _generate_smart_recommendations(self, incident: IncidentMemory, similar: List[Dict]) -> List[str]:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØµÙŠØ§Øª Ø°ÙƒÙŠØ©"""
        recommendations = []
        
        if len(similar) >= 3:
            recommendations.append("âš ï¸ Ù†Ù…Ø· Ù…ØªÙƒØ±Ø± Ù…ÙƒØªØ´Ù - ÙŠØªØ·Ù„Ø¨ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø¹Ø§Ø¬Ù„Ø©")
            recommendations.append("Ù…Ø±Ø§Ø¬Ø¹Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø³Ù„Ø§Ù…Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¬Ø§Ù„")
        
        recommendations.extend(incident.prevention_measures[:3])
        
        return recommendations
    
    def _assess_organizational_impact(self, incident: IncidentMemory) -> Dict:
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠ"""
        return {
            "safety_culture_impact": "high" if incident.severity > 7 else "medium",
            "learning_value": "high" if len(incident.lessons_learned) > 3 else "medium",
            "prevention_priority": "urgent" if incident.severity > 8 else "normal"
        }
    
    def _analyze_prevention_success(self, near_miss: NearMiss) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ù†Ø¬Ø§Ø­ Ø§Ù„ÙˆÙ‚Ø§ÙŠØ©"""
        return {
            "insights": [
                f"Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ø­Ø§Ø³Ù…: {factor}" for factor in near_miss.prevented_by
            ],
            "success_factors": near_miss.prevented_by,
            "replication_guide": [
                f"ØªØ·Ø¨ÙŠÙ‚ {factor} ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©" 
                for factor in near_miss.prevented_by
            ]
        }
    
    def _generate_behavior_recommendations(self, behavior_type: str, risk_level: float) -> List[str]:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØµÙŠØ§Øª Ø³Ù„ÙˆÙƒÙŠØ©"""
        recommendations = []
        
        if risk_level > 70:
            recommendations.append("ØªØ¯Ø®Ù„ ÙÙˆØ±ÙŠ Ù…Ø·Ù„ÙˆØ¨")
            recommendations.append("ØªØ¯Ø±ÙŠØ¨ ØªØµØ­ÙŠØ­ÙŠ")
        elif risk_level > 40:
            recommendations.append("Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØªÙˆØ¬ÙŠÙ‡")
            recommendations.append("ØªØ°ÙƒÙŠØ± Ø¨Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª")
        else:
            recommendations.append("Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©")
        
        return recommendations
    
    def _analyze_behavior_trend(self, pattern: BehaviorPattern) -> str:
        """ØªØ­Ù„ÙŠÙ„ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³Ù„ÙˆÙƒ"""
        if pattern.frequency > 20:
            return "Ù…ØªØ²Ø§ÙŠØ¯ Ø¨Ø´ÙƒÙ„ Ù…Ù‚Ù„Ù‚"
        elif pattern.frequency > 10:
            return "Ù…ØªØ²Ø§ÙŠØ¯"
        else:
            return "Ù…Ø³ØªÙ‚Ø±"
    
    def _assess_intervention_need(self, pattern: BehaviorPattern) -> bool:
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ù„ØªØ¯Ø®Ù„"""
        return pattern.risk_level > 60 and pattern.frequency > 10
    
    def _get_most_common_incidents(self) -> List[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙƒØ«Ø± Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø´ÙŠÙˆØ¹Ø§Ù‹"""
        incident_types = defaultdict(int)
        for incident in self.incident_memory:
            incident_types[incident.incident_type] += 1
        
        return [
            {"type": itype, "count": count}
            for itype, count in sorted(incident_types.items(), key=lambda x: x[1], reverse=True)[:5]
        ]
    
    def _get_top_root_causes(self) -> List[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙƒØ«Ø± Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠØ©"""
        causes = defaultdict(int)
        for incident in self.incident_memory:
            for cause in incident.root_causes:
                causes[cause] += 1
        
        return [
            {"cause": cause, "frequency": freq}
            for cause, freq in sorted(causes.items(), key=lambda x: x[1], reverse=True)[:5]
        ]
    
    def _get_effective_preventions(self) -> List[str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ÙˆÙ‚Ø§Ø¦ÙŠØ© Ø§Ù„Ø£ÙƒØ«Ø± ÙØ¹Ø§Ù„ÙŠØ©"""
        # Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Near Misses
        effective = defaultdict(int)
        for nm in self.near_misses:
            for prevention in nm.prevented_by:
                effective[prevention] += 1
        
        return [
            f"{prev} (Ù…Ù†Ø¹ {count} Ø­Ø§Ø¯Ø« Ù…Ø­ØªÙ…Ù„)"
            for prev, count in sorted(effective.items(), key=lambda x: x[1], reverse=True)[:5]
        ]
    
    def _compile_key_lessons(self) -> List[str]:
        """ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
        all_lessons = []
        for incident in self.incident_memory:
            all_lessons.extend(incident.lessons_learned)
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø± ÙˆØ§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹
        lesson_counts = defaultdict(int)
        for lesson in all_lessons:
            lesson_counts[lesson] += 1
        
        return [
            lesson for lesson, count in sorted(lesson_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        ]
    
    def _generate_strategic_recommendations(self) -> List[str]:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØµÙŠØ§Øª Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©"""
        recommendations = [
            "Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„ÙˆÙ‚Ø§ÙŠØ© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø±Ø¯ Ø§Ù„ÙØ¹Ù„",
            "Ø¨Ù†Ø§Ø¡ Ø«Ù‚Ø§ÙØ© Ø§Ù„Ø³Ù„Ø§Ù…Ø© Ù…Ù† Ø®Ù„Ø§Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±",
            "Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§"
        ]
        
        # Ø¥Ø¶Ø§ÙØ© ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if self.organizational_memory["total_near_misses"] > self.organizational_memory["total_incidents"] * 2:
            recommendations.append("âœ“ Ø«Ù‚Ø§ÙØ© Ø§Ù„Ø¥Ø¨Ù„Ø§Øº Ù…Ù…ØªØ§Ø²Ø© - Ø§Ø³ØªÙ…Ø±ÙˆØ§")
        else:
            recommendations.append("ØªØ´Ø¬ÙŠØ¹ Ø§Ù„Ø¥Ø¨Ù„Ø§Øº Ø¹Ù† Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„ØªÙŠ ÙƒØ§Ø¯Øª Ø£Ù† ØªÙ‚Ø¹")
        
        return recommendations
    
    def _calculate_performance_metrics(self) -> Dict:
        """Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        total_events = len(self.incident_memory) + len(self.near_misses)
        
        return {
            "near_miss_to_incident_ratio": round(
                len(self.near_misses) / len(self.incident_memory), 2
            ) if self.incident_memory else 0,
            "learning_rate": round(total_events / max(len(self.project_knowledge), 1), 2),
            "pattern_detection_rate": round(
                len(self.behavior_patterns) / max(total_events, 1) * 100, 2
            )
        }
    
    def _track_improvement(self) -> Dict:
        """ØªØªØ¨Ø¹ Ø§Ù„ØªØ­Ø³Ù†"""
        if len(self.incident_memory) < 10:
            return {"status": "insufficient_data"}
        
        # ØªÙ‚Ø³ÙŠÙ… Ø¥Ù„Ù‰ ÙØªØ±ØªÙŠÙ†
        mid_point = len(self.incident_memory) // 2
        old_incidents = self.incident_memory[:mid_point]
        recent_incidents = self.incident_memory[mid_point:]
        
        old_avg_severity = np.mean([inc.severity for inc in old_incidents])
        recent_avg_severity = np.mean([inc.severity for inc in recent_incidents])
        
        improvement = old_avg_severity - recent_avg_severity
        
        return {
            "old_average_severity": round(old_avg_severity, 2),
            "recent_average_severity": round(recent_avg_severity, 2),
            "improvement": round(improvement, 2),
            "improvement_percent": round(improvement / old_avg_severity * 100, 2) if old_avg_severity > 0 else 0,
            "trend": "ØªØ­Ø³Ù†" if improvement > 0 else "Ø«Ø§Ø¨Øª" if improvement == 0 else "ØªØ¯Ù‡ÙˆØ±"
        }
    
    def _find_similar_projects(self, project_config: Dict) -> List[Dict]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø´Ø§Ø±ÙŠØ¹ Ù…Ø´Ø§Ø¨Ù‡Ø©"""
        similar = []
        project_type = project_config.get('type')
        
        for proj_id, proj_data in self.project_knowledge.items():
            if proj_data['config'].get('type') == project_type:
                similar.append({
                    "project_id": proj_id,
                    "type": project_type
                })
        
        return similar
    
    def _is_relevant_to_project(self, incident: IncidentMemory, project_config: Dict) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø© Ø§Ù„Ø­Ø§Ø¯Ø« Ø¨Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"""
        # Ø¨Ø³ÙŠØ·: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ´Ø§Ø¨Ù‡ ÙÙŠ Ø§Ù„Ù†ÙˆØ¹
        return True  # ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙØ¹Ù„ÙŠØŒ Ø³ÙŠÙƒÙˆÙ† Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ø§Ù‹
    
    def _generate_smart_safety_plan(self, project_config: Dict, lessons: List[str]) -> Dict:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø·Ø© Ø³Ù„Ø§Ù…Ø© Ø°ÙƒÙŠØ©"""
        return {
            "preventive_measures": list(set(lessons))[:10],
            "inspection_schedule": "ÙŠÙˆÙ…ÙŠ",
            "training_requirements": ["ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ", "ØªØ¯Ø±ÙŠØ¨ Ø®Ø§Øµ Ø¨Ø§Ù„Ù…Ø¹Ø¯Ø§Øª"],
            "emergency_procedures": ["Ø¥Ø®Ù„Ø§Ø¡", "Ø¥Ø³Ø¹Ø§ÙØ§Øª Ø£ÙˆÙ„ÙŠØ©", "Ø¥Ø®Ù…Ø§Ø¯ Ø­Ø±ÙŠÙ‚"]
        }
    
    def _predict_project_risks(self, project_config: Dict) -> List[Dict]:
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"""
        risks = []
        
        # Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        incident_types = defaultdict(int)
        for incident in self.incident_memory:
            incident_types[incident.incident_type] += 1
        
        for itype, count in sorted(incident_types.items(), key=lambda x: x[1], reverse=True)[:5]:
            risks.append({
                "risk_type": itype,
                "probability": min(count / len(self.incident_memory) * 100, 90),
                "historical_occurrences": count
            })
        
        return risks
    
    def _estimate_safety_improvement(self, project_config: Dict, lessons: List[str]) -> str:
        """ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ØªØ­Ø³Ù† ÙÙŠ Ø§Ù„Ø³Ù„Ø§Ù…Ø©"""
        improvement_percent = len(set(lessons)) * 5  # ØªÙ‚Ø¯ÙŠØ±
        return f"{min(improvement_percent, 80)}% ØªØ­Ø³Ù† Ù…ØªÙˆÙ‚Ø¹"
    
    def _identify_success_factors(self) -> List[str]:
        """ØªØ­Ø¯ÙŠØ¯ Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­"""
        return [
            "Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³ØªÙ…Ø±",
            "Ø§Ù„ØªÙØªÙŠØ´ Ø§Ù„Ø¯ÙˆØ±ÙŠ",
            "Ø«Ù‚Ø§ÙØ© Ø§Ù„Ø¥Ø¨Ù„Ø§Øº Ø§Ù„Ù…ÙØªÙˆØ­Ø©",
            "Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø­Ø¯ÙŠØ«Ø©"
        ]
    
    def _identify_failure_points(self) -> List[str]:
        """ØªØ­Ø¯ÙŠØ¯ Ù†Ù‚Ø§Ø· Ø§Ù„ÙØ´Ù„"""
        return [
            "Ù†Ù‚Øµ Ø§Ù„ØªØ¯Ø±ÙŠØ¨",
            "Ø¥Ù‡Ù…Ø§Ù„ Ø§Ù„ØµÙŠØ§Ù†Ø©",
            "Ø¹Ø¯Ù… Ø§ØªØ¨Ø§Ø¹ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª"
        ]
    
    def _extract_best_practices(self) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª"""
        return [
            "Ø§Ù„ØªØ®Ø·ÙŠØ· Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡",
            "Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø©",
            "Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©",
            "ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ø¹Ù…Ø§Ù„ Ù…Ù† Ø§Ù„Ø¥Ø¨Ù„Ø§Øº"
        ]
    
    def _analyze_cross_project_risks(self) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø¹Ø¨Ø± Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹"""
        return {
            "common_risks": ["Ø§Ù„Ø³Ù‚ÙˆØ·", "Ø§Ù„Ù…Ø¹Ø¯Ø§Øª", "Ø§Ù„Ø­Ø±ÙŠÙ‚"],
            "emerging_risks": ["Ø§Ù„Ø¥Ø¬Ù‡Ø§Ø¯", "Ø³ÙˆØ¡ Ø§Ù„ØªÙˆØ§ØµÙ„"]
        }
    
    def _generate_future_recommendations(self) -> List[str]:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØµÙŠØ§Øª Ù„Ù„Ù…Ø³ØªÙ‚Ø¨Ù„"""
        return [
            "Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± ÙÙŠ Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø°ÙƒÙŠØ©",
            "Ø¨Ù†Ø§Ø¡ Ø«Ù‚Ø§ÙØ© Ø§Ù„Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ù‚ÙˆÙŠØ©",
            "Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³ØªÙ…Ø± ÙˆØ§Ù„Ù…ØªØ·ÙˆØ±"
        ]


# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    brain = AISafetyBrain()
    
    # Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø­Ø§Ø¯Ø«
    incident_result = brain.learn_from_incident({
        "type": "Ø³Ù‚ÙˆØ· Ù…Ù† Ø§Ø±ØªÙØ§Ø¹",
        "location": "Ø§Ù„Ø·Ø§Ø¨Ù‚ Ø§Ù„Ø«Ø§Ù„Ø«",
        "severity": 8.5,
        "root_causes": ["Ø¹Ø¯Ù… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø¯Ø§Øª Ø§Ù„Ø­Ù…Ø§ÙŠØ©", "Ù†Ù‚Øµ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"],
        "consequences": ["Ø¥ØµØ§Ø¨Ø© Ø®Ø·ÙŠØ±Ø©", "ØªÙˆÙ‚Ù Ø§Ù„Ø¹Ù…Ù„"]
    })
    
    print(json.dumps(incident_result, indent=2, ensure_ascii=False))
